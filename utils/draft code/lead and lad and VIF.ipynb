{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:#00BFFF\">\n",
    "\n",
    "##### Variance Inflation Factor (VIF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "VIF measures how much the variance of an estimated regression coefficient increases if the predictors are correlated. A VIF value greater than 10 is often considered indicative of multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# X = joined_dataset.copy()\n",
    "\n",
    "# pce = X['PCE']\n",
    "\n",
    "# # Exclude 'PCE' from VIF calculation but keep it in the dataset\n",
    "# X_without_PCE = X.drop(columns=['PCE']) if 'PCE' in X.columns else X.copy()\n",
    "\n",
    "# # Handle missing (NaN) and infinite (inf) values\n",
    "# X_without_PCE = X_without_PCE.fillna(X_without_PCE.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vif_data = pd.DataFrame()\n",
    "# vif_data[\"feature\"] = X_without_PCE.columns\n",
    "# vif_data[\"VIF\"] = [variance_inflation_factor(X_without_PCE.values, i) for i in range(X_without_PCE.shape[1])]\n",
    "# vif_data = vif_data.sort_values(by='VIF', ascending=False)\n",
    "# print(vif_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Filtering VIF values above 10\n",
    "# df_filtered = vif_data[vif_data['VIF'] > 10]\n",
    "\n",
    "# # Creating the lollipop chart\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.stem(df_filtered['feature'], df_filtered['VIF'], basefmt=\" \") #, use_line_collection=True)\n",
    "\n",
    "# # Customizing the plot with the color scheme\n",
    "# plt.scatter(df_filtered['feature'], df_filtered['VIF'], color='red', s=100, label='VIF > 10', zorder=5)\n",
    "# plt.plot(df_filtered['feature'], df_filtered['VIF'], color='grey', linestyle='-', linewidth=1, zorder=3)\n",
    "\n",
    "# # Adding text labels for each value\n",
    "# for i, row in df_filtered.iterrows():\n",
    "#     plt.text(row['feature'], row['VIF'], f\"  {row['VIF']:.2f}\", va='center', ha='left', backgroundcolor='white', fontsize=8)\n",
    "\n",
    "# # Enhancing the design\n",
    "# plt.xticks(rotation=45, ha=\"right\")\n",
    "# plt.ylabel('VIF Value')\n",
    "# plt.title('Variance Inflation Factor (VIF): Indicators with highest Colinearity')\n",
    "# plt.grid(axis='y', linestyle='--', linewidth=0.7, color='grey', zorder=0)\n",
    "# plt.tight_layout()\n",
    "\n",
    "# # Hide the left, top, and right frame lines\n",
    "# plt.gca().spines['top'].set_visible(False)\n",
    "# plt.gca().spines['right'].set_visible(False)\n",
    "# plt.gca().spines['left'].set_visible(False)\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:#00BFFF\">\n",
    "\n",
    "**Handling highest VIF indciators**\n",
    "</div>\n",
    "\n",
    "- This code snippet performs a Variance Inflation Factor (VIF) analysis to identify and remove multicollinear features from a dataset, except for those specifically ignored. \n",
    "- It iterates through the dataset, calculating VIFs for all features not in the `ignored_columns` list. \n",
    "- If a feature's VIF exceeds 20, indicating high multicollinearity, and it's not on the ignored list, that feature is dropped from the dataset. \n",
    "- The process repeats until no feature's VIF exceeds 20, ensuring the remaining dataset has reduced multicollinearity, enhancing model reliability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a list of columns to ignore in the VIF calculation\n",
    "\n",
    "# ignored_columns = []#[\"Civilian Unemployment Rate\",\"Civilian Employment\",\n",
    "#                     # \"Housing Starts: Total New Privately Owned\",\n",
    "#                     # \"Civilian Labor Force\",\"CPI_Index\",\"IP Index\",\n",
    "#                     # 'Personal Cons. Expend.: Chain Index'\n",
    "#                     # ]  \n",
    "\n",
    "# # A Loop to Find and drop the variable with the highest VIF if it's not in the ignored list\n",
    "\n",
    "# while True:\n",
    "#     # Calculate VIF for features not in the ignored list\n",
    "#     vif_data = pd.DataFrame()\n",
    "#     vif_data[\"feature\"] = [column for column in X_without_PCE.columns if column not in ignored_columns]\n",
    "#     vif_data[\"VIF\"] = [variance_inflation_factor(X_without_PCE[vif_data[\"feature\"]].values, i) for i in range(len(vif_data[\"feature\"]))]\n",
    "\n",
    "#     # Find and drop the variable with the highest VIF if it's not in the ignored list\n",
    "#     max_vif = vif_data[\"VIF\"].max()\n",
    "#     if max_vif > 10:  \n",
    "#         feature_to_drop = vif_data.sort_values(\"VIF\", ascending=False).iloc[0][\"feature\"]\n",
    "#         if feature_to_drop not in ignored_columns:\n",
    "#             X_without_PCE.drop(columns=[feature_to_drop], inplace=True)\n",
    "#             print(f\"Dropping {feature_to_drop} with VIF: {max_vif}\")\n",
    "#         else:\n",
    "#             # If the top VIF feature is in the ignore list, remove it from the VIF dataframe and continue\n",
    "#             vif_data = vif_data[vif_data[\"feature\"] != feature_to_drop]\n",
    "#     else:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:#00BFFF\">\n",
    "\n",
    "##### Lead and Lag Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Time Lag Analysis**:\n",
    "   - **Cross-Correlation**: Examine the cross-correlation function (CCF) between 'PCE' and other indicators to identify potential lead-lag relationships.\n",
    "\n",
    "- **Technique**: Analysing the time-shifted relationships between consumer spending and the proxies to identify if any indicators consistently lead or lag behind consumer spending patterns.\n",
    "- **Objective**: To discover predictive relationships where certain proxies might signal changes in consumer spending ahead of time or respond with a delay. *While relevant, the Lead and Lag Analysis could become complex and time-consuming. We need to ensure that it directly contributes to the goal of identifying proxies.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lead_lag_analysis(dataset, target_column, variable_list, max_lag=3):\n",
    "#     \"\"\"\n",
    "#     Perform lead and lag analysis for specified variables against a target column.\n",
    "    \n",
    "#     :param dataset: Pandas DataFrame\n",
    "#     :param target_column: Column name of the target variable\n",
    "#     :param variable_list: List of column names to analyze\n",
    "#     :param max_lag: Maximum number of periods for lead/lag\n",
    "#     :return: DataFrame with correlation results\n",
    "#     \"\"\"\n",
    "#     results = []\n",
    "\n",
    "#     for variable in variable_list:\n",
    "#         for lag in range(-max_lag, max_lag + 1):\n",
    "#             if lag == 0:\n",
    "#                 # Contemporaneous correlation\n",
    "#                 corr = dataset[variable].corr(dataset[target_column])\n",
    "#             else:\n",
    "#                 # Lead/Lag correlation\n",
    "#                 shifted = dataset[variable].shift(-lag)\n",
    "#                 corr = shifted.corr(dataset[target_column])\n",
    "\n",
    "#             results.append({'Variable': variable, 'Lag': lag, 'Correlation': corr})\n",
    "\n",
    "#     return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Choose variables (excluding 'PCE')\n",
    "# variables_to_analyze = refined_dataset.columns.drop('PCE')\n",
    "\n",
    "# # Perform lead and lag analysis\n",
    "# lead_lag_results = lead_lag_analysis(refined_dataset, 'PCE', variables_to_analyze, max_lag=4)\n",
    "\n",
    "# # Display the results\n",
    "# print(lead_lag_results.sort_values(by='Correlation', ascending=False))\n",
    "\n",
    "# # Filter for indicators with a lag of 1 and high correlation\n",
    "# filtered_results = lead_lag_results[lead_lag_results['Lag'].between(0,1)] \n",
    "\n",
    "# # Sort by correlation strength\n",
    "# filtered_results = filtered_results.sort_values(by='Correlation', ascending=False)\n",
    "\n",
    "# # Extract variable names from the filtered results\n",
    "# variables_for_nowcasting = filtered_results['Variable'].unique().tolist()\n",
    "\n",
    "# # Ensure 'PCE' is included in the list\n",
    "# if 'PCE' not in variables_for_nowcasting:\n",
    "#     variables_for_nowcasting.append('PCE')\n",
    "\n",
    "# # Filter refined_dataset to include only the selected variables\n",
    "# filtered_refined_dataset = refined_dataset[variables_for_nowcasting]\n",
    "\n",
    "# # Calculate correlations for the selected variables\n",
    "# filtered_top_correlations_refined = calculate_sorted_correlations(filtered_refined_dataset, 'PCE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_correlations = calculate_sorted_correlations(filtered_refined_dataset, 'PCE')\n",
    "\n",
    "# plot_correlation_circle_heatmap(filtered_refined_dataset, top_correlations, top_n=30, fig_title='Original Correlation Circle Heatmap')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
